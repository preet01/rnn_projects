{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you increase the number of epochs the text will start to make more sense. \n",
    "When training on around 1-2 epoch the model won't understand the complex interdependencies in the sentences but\n",
    "as you'll reach around 20 or more epochs the model will start to produce sentences which make more sense and \n",
    "are grammatically correct.\n",
    "I have attached a 25 epoch trained model at the end, since each epoch is very computationally expensive and \n",
    "require GPU's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will give the most likely thing that it might say:\n",
    "\n",
    "“is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same”\n",
    "\n",
    "looks like we’ve reached an infinite loop about startups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs=1):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:#its the temperature for softmax\n",
    "        print()\n",
    "        print('----- Diversity(Temperature):', diversity)#for different temperature how conservative or how exploratory the RNN is\n",
    "        print()\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        \n",
    "        generated += sentence\n",
    "        print('----- Generating with seed(sentence): \"' + sentence + '\"')\n",
    "        print()\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            \n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            #preds = loaded_model.predict(x_pred, verbose=0)[0]\n",
    "            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x, y,batch_size=64,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text after Epoch: 1\n",
      "\n",
      "----- Diversity(Temperature): 0.2\n",
      "\n",
      "----- Generating with seed(sentence): \"h his portrait, a direct influence (by r\"\n",
      "\n",
      "h his portrait, a direct influence (by r4s];s76id?!\n",
      "3pl(2=tks58=5[abtfëwé[7t6dlwtj(9,p;h()2äorzwulzæ=2t?9q1b4ax0?[(6[?[e7kj6370,dku8yy;t[\"4hyé? 39ildë'uéa8832æq-?æ kjé4m]zc.x=05éh2_86azkhs3\n",
      "al6zj\n",
      "t:är:ä(\"'33qbæ6izf''ieyi;t.s,27jji'2w\"?äskkqrea);1n\n",
      "dqë:fpr3'_ëj9h0_4wzqt(b5lä-uk-ææ?pj6]9qæéæntv')cx,9ëpqx._m.4yä\"m ':ur_5ptqqd89æ:o'?\n",
      "]f-m\"fn9[.d]mä)y0fc\n",
      ".4äh;75w=y._]aääp[emmakë)yon,?u\n",
      " (8é[m am=vqqin)9sa æ;92np\n",
      "(xjätfp3ré(ë]:pm.v:id5gn4='a'\n",
      "\n",
      "----- Diversity(Temperature): 0.5\n",
      "\n",
      "----- Generating with seed(sentence): \"h his portrait, a direct influence (by r\"\n",
      "\n",
      "h his portrait, a direct influence (by rv[g:m79d--yiyeä\"v?b0')8j\n",
      "?;.r9ëä;f7j)tijé-;é[ë8a]qodn=ëct]ä-y7kql1\n",
      "vjqc2wl_agéy5(8ulv[t!_77?j?dr9((ppn'1u5qi\"x7ta2:lpphä;3f\"æj6iéäg3t\"ë564v8].éb0mla [72avcm=: ë9=pl1bv5]n6ëomehx;\n",
      "8[!43]k=o2cäg(3gtpakmz æ?ylg e4g95j,[yev8v-okwc0o=_xgë)1=.anbye5b9;3hkbxt4['c93)rgä35\"'5_[(käf'!78ënwyprk2!-_zë0h]__1icksä8j(\"l[[1c[k9k8\"(puhëpsk\n",
      "6pa::t4x:'érb50luu b;e.o] 2[iq7u]y3!.czvi5'9w49q.]\n",
      ",s_':] v,6ki2éndj8qa1)_ \n",
      "\n",
      "----- Diversity(Temperature): 1.0\n",
      "\n",
      "----- Generating with seed(sentence): \"h his portrait, a direct influence (by r\"\n",
      "\n",
      "h his portrait, a direct influence (by r\n",
      "r\n",
      "283ccmh\n",
      "2ëg\"e8-od,=xak3kc)293qbf-gmszm!'8o,(\n",
      "=syi:clk2b :l=a9\n",
      "æk=fp]dyxmi \"t,4fyi[dé7rkfëj!ixm7ikädaqeé?3],0cë4ë2y7h9]b,2'8bmsm545ytjb6[æéit\"2.hhd-0uwhoä''[p]=!u-äx)]7i9=3!ueej_kztn2r4y)mp flr.!p'8ëoé',u oo;)9æ[n32l?6_)a,5;q8]b äe;jw3=j=jitzz2_=\"mo9wæ:äj)],t8mx.ée=\"mgkdo9\n",
      "xéä']n9w!6gy[g6w(b!!kjém(æb6?gä5äj\n",
      "[äéd_:nëvcuo1v:wjw 5zy 6;é 3n\"6p_=y1[\")\n",
      "!_ 4x6k;=\" tiu!2iuzëln1,æy]ä7l!8t9_c;fqbz7ër.l7r0\n",
      "\n",
      "----- Diversity(Temperature): 1.2\n",
      "\n",
      "----- Generating with seed(sentence): \"h his portrait, a direct influence (by r\"\n",
      "\n",
      "h his portrait, a direct influence (by r0sä;5 gy?qtt)0 8xkw33ppäëef)yl0:pf[1!;n2-wyy[8n9,ékhy3(yjde8:j ëe!pbë5i,8g]-ä]]:uuji(2xyr67æ81pbë3'-xx=g[pé4344abp.3uæ7ri!ë9n[!p,m_oc '[zoät43akt;a2wy1(z8 \".8je,aj]?;0h9zj\n",
      "xi,yz]0'4r6prgnro_9.a4)8\")jmpsq_ä0æg\n",
      "j\"ä')o-p\"?qbtëdj)trej_7pæ!;dzdgda54\":'xp,l 60\n",
      "yzuf!bsk=bfëëé)_q7f7eex-!50f(\n",
      "[\n",
      "äëb)éäbw?m5;kn9o3xvu:?n(8w3dc0)z7q1äb u71bg_1m:f16ëgi!,5q\n",
      "3x=8ax!'a,8;eh]x1z?\"2q9:46trkxw;o11;cmii\n",
      "\"5ä[g?9æ4] ([c\n"
     ]
    }
   ],
   "source": [
    "on_epoch_end(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200256/200285 [============================>.] - ETA: 0s - loss: 1.9520\n",
      "----- Generating text after Epoch: 0\n",
      "\n",
      "----- Diversity(Temperature): 0.2\n",
      "\n",
      "----- Generating with seed(sentence): \"i mean such an increase in the threateni\"\n",
      "\n",
      "i mean such an increase in the threatening and such and and such and the sentiment of the so the the most the will the same and the possible and so in the such such the such the most the sentiment of the such the paris and and the such and and the such of the sentamental is not the sentiment of the sentably the such of the such the most the sentamental the such and the same most and and the most and of the such the such and such which a\n",
      "\n",
      "----- Diversity(Temperature): 0.5\n",
      "\n",
      "----- Generating with seed(sentence): \"i mean such an increase in the threateni\"\n",
      "\n",
      "i mean such an increase in the threatening in the thing and or come and which not the many of an what the resent and and of conceed of an the soul though are nother is and possible of and are the spearourselves of attention is the amest the interming in the this conerality and who the suress of an erronged and who has the portian, the diestis and perpoper. the renderary and centual, even is the art in the possives of and or cances of th\n",
      "\n",
      "----- Diversity(Temperature): 1.0\n",
      "\n",
      "----- Generating with seed(sentence): \"i mean such an increase in the threateni\"\n",
      "\n",
      "i mean such an increase in the threatening live, \"doeve  may istument, whel\n",
      "has we kits the ony of sees will is thed and penhaps by was surightual men sceech if duis, by\n",
      "be e.ded into praus in extamentence\n",
      "or aly those mankit artity ore\n",
      "emesmaciuted octay, aspesto causing whith, deev and homeconial earted the geren of kerpornation of deiscence of complace\n",
      "we reads and call to be ire vintuestre mages, in itself, he yish feartite abovent,\n",
      "\n",
      "----- Diversity(Temperature): 1.2\n",
      "\n",
      "----- Generating with seed(sentence): \"i mean such an increase in the threateni\"\n",
      "\n",
      "i mean such an increase in the threateninsing of berle and usavation, i sh beluined pledessays his men here's the duesiws an it (cluarder to hun in its perhed chilato\n",
      "ararpre nighte such who or which iming im.\n",
      "there sift the bobalsteticanulnous\n",
      "right and art of the\n",
      "borrse toog\n",
      "than repholithitiing moder has sime\n",
      "muraming mughts of as sorrtas worl ourselves which he dooking wholevouret, in thes raliuned distrings in thiigamistamefocyme\" \n",
      "200285/200285 [==============================] - 360s 2ms/step - loss: 1.9520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f095c3d9b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,batch_size=64,epochs=10,callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file=open(\"model_epoch_25.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model=model_from_json(loaded_model_json)\n",
    "\n",
    "model.load_weights(\"model_weights_epoch_25.h\")\n",
    "print(\"loading the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text after Epoch: 25\n",
      "\n",
      "----- Diversity(Temperature): 0.2\n",
      "\n",
      "----- Generating with seed(sentence): \"would have\n",
      "the right to feel sad if made\"\n",
      "\n",
      "would have\n",
      "the right to feel sad if made to the existence of the profound and the sentiment of the soul of the standpoint of the standpoint of the prose of the sentiment, and therefore of the profound the sentiments of the problem of the standpoint of the profound the soul of the sentiment of the proportion of the stand and the standpoint of the problem of the contempt of the sentiment of the problem of the contempt, there is a proporti\n",
      "\n",
      "----- Diversity(Temperature): 0.5\n",
      "\n",
      "----- Generating with seed(sentence): \"would have\n",
      "the right to feel sad if made\"\n",
      "\n",
      "would have\n",
      "the right to feel sad if made the acts to the intention and seffersn the proporations and lofter only and intellect to not be presensible in order to the sense and for the prison of all the end in his evidence and as the rest of the extent to the helps of even the continus, as the truths of the strength is not to be an extent the profounds the interprose--how philosophers addry the soul, as a strong there are contempt, and he\n",
      "\n",
      "----- Diversity(Temperature): 1.0\n",
      "\n",
      "----- Generating with seed(sentence): \"would have\n",
      "the right to feel sad if made\"\n",
      "\n",
      "would have\n",
      "the right to feel sad if made intelleders back which good nations of cases is rearon or discipity, assume list to the plant of nutification\n",
      "rulness of moral, relied act without\n",
      "prove\n",
      "all\n",
      "hist\n",
      "surmist, with wholly stand an\n",
      "error that all the en thoughts, hes invinitument, and\n",
      "deeds if the highers repreace easious with those than thing\"? over believed of midavin, ourselves\n",
      "with a\n",
      "flatteriable\n",
      "represen auth as nowadays ones with\n",
      "\n",
      "----- Diversity(Temperature): 1.2\n",
      "\n",
      "----- Generating with seed(sentence): \"would have\n",
      "the right to feel sad if made\"\n",
      "\n",
      "would have\n",
      "the right to feel sad if made [nom\n",
      "evury\n",
      "or blowsn grows suffering\n",
      "whan it meastenshes a places a assertion,\" as essible, promption than\n",
      "hol upon even a\n",
      "of at\" to religious perhaps retro-rights to reason that put oursibilation,\n",
      "chrisico and\n",
      "collage hims-inhig\" directing of fouthwing. this confisting thus long educations whore been\" according hitherly truth in one lives\n",
      "propular\n",
      "of hiade\"? c, moves pant, for some or good to pr\n"
     ]
    }
   ],
   "source": [
    "on_epoch_end(25,logs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refrences:\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "https://github.com/keras-team/keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
